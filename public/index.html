
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Hack hack hack...</title>
  <meta name="author" content="Adam Jonas">

  
  <meta name="description" content="Network partitioning causing exchange issues on rabbitmq this was after netowrk maintenance
solution was to delete exchange which then is &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="google-site-verification" content="bPr3kB-X2beP1o9InhOKH9ci-gljU3a7NLEeap4urfc" />

  
  <link rel="canonical" href="http://adamjonas.com/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="/javascripts/ender.js"></script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <link href="/atom.xml" rel="alternate" title="Hack hack hack..." type="application/atom+xml">
  <link href='http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  
 <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-35486864-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body   >
  <header role="banner"><hgroup>
  <div id="logo">
  	<div id="logoLeft">{</div>
  	<div id="logoText">Adam Jonas</div>
  	<div id="logoRight">}</div>
  	<div class="clear"></div>
  </div>
  <h1><a href="/">Hack hack hack...</a></h1>
  
    <h2>An open journal-- some of it written for you, but most of it is for me.</h2>
  
  <div class="clear"></div>
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://www.google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:adamjonas.com" />
    <input class="search" type="text" name="q" results="100" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/about">About</a></li>
  <li><a href="/glossary">Glossary</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <!-- Now we're back to normal posts. Note the links used under href in both headers.-->
        <h1 class="entry-title"><a href="/blog/more-ops-notes/">More Ops Notes</a></h1>
      
    
    
      <p class="meta">
        








  


<time datetime="2017-03-29T16:18:00-04:00" pubdate data-updated="true">Mar 29<span>th</span>, 2017</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h2>Network partitioning causing exchange issues on rabbitmq</h2>

<ul>
<li>this was after netowrk maintenance</li>
<li>solution was to delete exchange which then is automatically added
back <a href="https://github.com/rabbitmq/rabbitmq-server/issues/887#issuecomment-290177962">documented here</a></li>
</ul>


<h2>Ubuntu 16</h2>

<ul>
<li>ubuntu 16 doesn&#8217;t ship with upstart so sysctld is what we&#8217;ll use to
control services. <a href="https://www.digitalocean.com/community/tutorials/how-to-use-systemctl-to-manage-systemd-services-and-units">systemctl commands</a>

<ul>
<li>can also run from <code>/etc/init.d/service start</code></li>
</ul>
</li>
<li>rsyslog is what we use to get the logs to papertrail</li>
<li>used the oracle version of Java 8</li>
</ul>


<h2>Digital ocean</h2>

<ul>
<li>backups (auto) are different than snapshots (not auto) and different
in pricing as well</li>
</ul>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <!-- Now we're back to normal posts. Note the links used under href in both headers.-->
        <h1 class="entry-title"><a href="/blog/project-aristole/">Project Aristole</a></h1>
      
    
    
      <p class="meta">
        








  


<time datetime="2017-03-27T11:49:00-04:00" pubdate data-updated="true">Mar 27<span>th</span>, 2017</time>
        
      </p>
    
  </header>


  <div class="entry-content"><ul>
<li><a href="https://www.nytimes.com/2016/02/28/magazine/what-google-learned-from-its-quest-to-build-the-perfect-team.html?_r=0">Quest to build the perfect team</a></li>
</ul>


<h2>Reading Notes</h2>

<ul>
<li>decentralized control</li>
<li>manager surveys

<ul>
<li>different mediums to collect feedback</li>
</ul>
</li>
<li>no exact patterns</li>
<li>rapport building -> chit chat, care about others as people as much
as co-workers

<ul>
<li>social sensitivity

<ul>
<li>reading the <a href="http://socialintelligence.labinthewild.org/mite/">Reading the Mind in the Eyes test</a></li>
</ul>
</li>
<li>trust</li>
</ul>
</li>
<li>groups norms are stronger than the individual, even if the
individual is strong, driven and accomplished</li>
<li>?what is data of a strong group?</li>
<li>following up on hurtful interactions (saying the things that go
unsaid)</li>
<li>Manager:

<ul>
<li>humility, my team is smarter than me -> vulnerability</li>
<li>fulfillment of creating a great team</li>
<li>setting communication norms</li>
<li>empathy norms and quick follow up</li>
</ul>
</li>
</ul>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <!-- Now we're back to normal posts. Note the links used under href in both headers.-->
        <h1 class="entry-title"><a href="/blog/crash-course/">Crash Course DevOps</a></h1>
      
    
    
      <p class="meta">
        








  


<time datetime="2017-03-20T11:12:00-04:00" pubdate data-updated="true">Mar 20<span>th</span>, 2017</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h2>Wires, cables and WiFi</h2>

<ul>
<li>Bits sent as light beams, no signal loss

<ul>
<li>faster than copper</li>
</ul>
</li>
<li>WiFi is radio and then translated into physical bits over the wires</li>
<li>Bitrate -> bits per second -> how fast it can transmit</li>
<li>bandwidth -> how much data can you receive over a period of time</li>
<li><p>latency -> how long it takes, more hops to talk to Seiji than
Kaitlin in the next room; ping time * distance</p></li>
<li><p><code>traceroute</code> to see hops</p></li>
</ul>


<h2>IP addresses and DNS</h2>

<ul>
<li>ISP</li>
<li>IP is a unique address

<ul>
<li>IPv4 - 4 billion unique addresses isn&#8217;t enough

<ul>
<li>32 bits, 8 octets</li>
<li>32 bits long, 8 bits for each part of each address</li>
<li>DHCP -> obtaining a lease renewal process on your network.</li>
<li>to the outside world, Flatiron has the same IP provided
by ISP</li>
<li>router provides guests with temporary IP depending on how long
your lease renewal is set</li>
<li>renegotiate IP
?- subnet mask</li>
<li>255.255.255.255 is the max it could go, based on the octet</li>
<li>static IP -> unique in the world</li>
<li>private IP -> re-use private IP addresses behind networks</li>
</ul>
</li>
</ul>
</li>
<li><p> IPv6 - 128 bits instead of 32</p>

<ul>
<li>hex representation to prevent us running out of static IPs</li>
<li><p>DNS servers are split up in TLDs</p>

<ul>
<li>DNS on a router</li>
</ul>
</li>
<li><p>google&#8217;s DNS will break it up by the TLD and domain</p></li>
<li><a href="http://www.macworld.com/article/2824564/slow-internet-edit-your-dns-settings.html">google DNS</a> versus open DNS</li>
<li>?www doesn&#8217;t mean anything any more, just another subdomain</li>
<li>?CS of how the domain names at the DNS are stored?</li>
</ul>
</li>
<li><p> TTL</p>

<ul>
<li>this record will expire at X time</li>
<li>set TTL to an hour, it won&#8217;t have to look it up for an hour</li>
<li>DNS propagation</li>
</ul>
</li>
<li><p>DNS -> record type</p>

<ul>
<li>A record -> address</li>
<li>maps the word name the domain to a physical IP address</li>
<li>PTR -> pointer -> the reverse, input IP and get the domain</li>
<li>FQDN -> A fully qualified domain name (<a href="http://stackoverflow.com/questions/19480767/domain-names-with-dots-at-the-end">FQDN</a>) is the complete domain name for a specific computer, or host, on the Internet.

<ul>
<li>Host name is gmail and .com is the TLD</li>
</ul>
</li>
<li>CNAME -> mail.google.com is a CNAME of googlemail.l.google.com.

<ul>
<li>A records should be unique</li>
</ul>
</li>
<li>why is there a dot at the end?

<ul>
<li>it is an absolute as opposed to the relative address</li>
</ul>
</li>
<li>want multiple MX records, redudency strategy</li>
</ul>
</li>
</ul>


<h2>Packet, routers and reliability</h2>

<ul>
<li>fault tolerant</li>
<li>TCP</li>
<li><p>?How do they determine the route?</p>

<ul>
<li>routers own the ISP and the companies that own them</li>
</ul>
</li>
<li><p>traceroute domain.com</p></li>
<li><p>wireshark is a GUI of <a href="https://danielmiessler.com/study/tcpdump/#gs.9p=ZVMQ"><code>tcpdump</code></a></p></li>
<li><p>IP address can change and it has a serial number or a MAC address
(hardware address)</p></li>
</ul>


<h2>HTTP &amp; HTML</h2>

<ul>
<li>SSL and TLS (successor)

<ul>
<li>http listens on 80 and https listens on 443</li>
<li>sslv3 has been deprecated</li>
</ul>
</li>
<li>certificate authority vouches for site</li>
<li>OpenSSL generates keys, authority will sign that</li>
<li>self-signed certs like for nagios or letsencrypt will work fine</li>
<li>SSLS

<ul>
<li>discrete logorithm problem</li>
</ul>
</li>
<li>handshake process -> how to keep box locked and send secret

<ul>
<li>put treasure in box, lock box, send to friend</li>
<li>friend puts lock on box, sends it back</li>
<li>I remove lock from box and send back</li>
<li>friend unlocks box</li>
</ul>
</li>
<li>SSH

<ul>
<li>ssh forwarding sends private key along</li>
<li>asymetric only used for authentication</li>
<li>symetric is then used for encryption and decryption</li>
</ul>
</li>
<li><a href="https://en.wikipedia.org/wiki/Bcrypt">bcrypt</a> is what we use for email</li>
</ul>


<h2>DDoS</h2>

<ul>
<li><a href="https://en.wikipedia.org/wiki/Domain_Name_System#DNS_resolvers">DNS resolvers</a> to amplify attack</li>
</ul>


<h2>DevinOps in review</h2>

<ul>
<li><a href="https://github.com/thiagopradi/octopus">Octopus gem</a> -> pooling, load balance select statements to read only
replicas</li>
<li>DB sharding

<ul>
<li>complex SQL joins, will put different tables in different DBs</li>
<li>replication</li>
</ul>
</li>
<li>floating IPs points to the master

<ul>
<li>static IP never changes</li>
<li>use floating IPs rather than DNS because of propogation</li>
</ul>
</li>
<li>usernames:

<ul>
<li>if you have a server on linux it should not be running on root</li>
<li>if it&#8217;s a system process then it would be ok to run on root</li>
<li>postgres is run as the postgres user

<ul>
<li>apache is run by deployer and passenger -> how ruby achieves
paralellization (a module for apache)</li>
</ul>
</li>
<li>deployer for Ironboard -> easy way to manage keys</li>
<li>how owns the process, who owns the directory where the config
files lives</li>
</ul>
</li>
<li><code>etc/passwd</code> -> all the users on the box and who is logged in</li>
<li>every service that has a port open to the internet it should have
its own user</li>
<li>username is usually the service name</li>
<li><code>/var</code> is usually the log directory</li>
<li><code>/etc</code> is usually the config directory</li>
<li>WAL-E

<ul>
<li>ship our binary logs we sent to s3</li>
<li><a href="https://en.wikipedia.org/wiki/Write-ahead_logging">write ahead logs</a> -> must be complete before actually modifies the
DB with a transaction. This is the mechanism for rollbacks.

<ul>
<li>master just sends the write-ahead logs to the slave which then
just replays them</li>
</ul>
</li>
</ul>
</li>
<li>Backups

<ul>
<li>take a base and then the have these WAL backups and send them off
and it will apply all the deltas</li>
<li>can give us point in time restoration</li>
<li>these logs will fill up our disk</li>
<li>? how long do we keep WAL-E</li>
<li>interface for deleting backups, s3 logs</li>
<li>config of pg is <code>pg_hba.conf</code></li>
<li>script to switch over primary/replication script turns <code>recovery.conf</code> to <code>recovery.done</code></li>
<li><code>failover.sh</code> on the other replica as root

<ul>
<li>breaks replication, now need to configure replication on the new
replication server</li>
</ul>
</li>
<li><a href="https://en.wikipedia.org/wiki/Iptables">iptables</a> -> firewall</li>
</ul>
</li>
</ul>


<h2>Permissions</h2>

<ul>
<li>User, Group, World -> multiple users on the same machine, make sure
processes don&#8217;t do stuff they aren&#8217;t supposed to</li>
<li>chmod 755, 644</li>
<li>all directories have to be 7

<ul>
<li>directories point to other files</li>
</ul>
</li>
<li>cd is a program that takes a directory (file) as an argument and
executes it</li>
<li><code>etc/sudoers</code> -> determines who has root permissions; visudo -> creates a backup and prevents brackage</li>
<li><code>useradd</code> give them a shell and name the user; want to add to the
chef script</li>
</ul>


<h2>load balancer</h2>

<ul>
<li>front-end is learn.co, terminating SSL, in the</li>
<li>backend -></li>
<li>should be root on</li>
</ul>


<h2>Debugging</h2>

<ul>
<li><code>passenger-status --show=requests</code></li>
<li><code>passenger-status</code></li>
</ul>


<h2>Automatic provisioning</h2>

<ul>
<li><a href="https://github.com/digitalocean/doctl">doctl</a></li>
<li><a href="https://github.com/petems/tugboat">tugboat</a></li>
</ul>


<h2>cron</h2>

<ul>
<li>sends mail</li>
</ul>


<h2>IDE backend</h2>

<ul>
<li>backend application -> IDE umbrella</li>
<li>main one is learn-ide-server cookbook</li>
<li>different chef servers</li>
<li>wombat</li>
<li>traffic cop</li>
<li>elixir-build01 -> build elixir on server because linux</li>
<li>new server needs to be added to <a href="https://github.com/flatiron-labs/students-chef-repo/tree/master/cookbooks/learn-ide-haproxy">HAproxy</a></li>
<li>lb -> <code>balance url_param token</code> hashing algorithm that determines
which server the IDE connects to based on their Learn oauth token. (Optimization -> make hashing algo
more granualar so that if a machine gets taken out the rotation, the
othere aren&#8217;t rebalanced as well</li>
<li>Load balance assignment is determined by dynect traffic management

<ul>
<li>own health monitoring</li>
</ul>
</li>
<li><a href="https://www.gluster.org/">gluster</a> is fancy NFS

<ul>
<li>RAID -> redundant array of independent disks</li>
</ul>
</li>
<li><a href="https://coreos.com/rkt/">rkt</a></li>
<li>PTY - psuedoterminal, terminal emulator, connect to an arbitrary shell</li>
<li>inotify -> FS event watcher</li>
<li>containerization

<ul>
<li><a href="https://en.wikipedia.org/wiki/Aufs">aufs</a> loser -> <a href="https://en.wikipedia.org/wiki/UnionFS">unionfs</a> winner that was merged into linux</li>
</ul>
</li>
<li>? do you bump archived tar&#8217;ed files when you archive again</li>
</ul>


<h2>IDE Umbrella</h2>

<ul>
<li>for adding IDE server (<a href="https://github.com/flatiron-labs/ide_umbrella/blob/master/config/prod.exs">node list</a>)</li>
<li>dependencies in <code>mix.exs</code>; <a href="https://github.com/ninenines/cowboy">cowboy</a> is the webserver, <a href="https://github.com/devinus/poolboy">poolboy</a></li>
<li>applications are like slightly fancy supervisors, <a href="https://github.com/bitwalker/distillery">distillery</a> release packaging</li>
<li><code>mix deps.get</code> -> get dependencies</li>
<li><code>iex -S mix</code></li>
<li><code>:cowboy.start</code> -> erlang library, cowboy is lib which is an atom</li>
<li><code>gen_server</code>, an abstraction on top of processes in general

<ul>
<li>provides state and a little behavior</li>
</ul>
</li>
<li><code>agent</code> is just for state</li>
<li>every connection gets its own process</li>
<li>distillery builds them

<ul>
<li>release -> full replacement of previous release, must restart</li>
<li>upgrade -> release plus upgrade instructions, relup file, modify
the code in memory -> hotswap; preferable to release</li>
<li><code>mix edeliver version qa</code></li>
<li><code>mix edeliver version production</code></li>
<li><code>mix edeliver build release</code></li>
<li><code>mix edeliver deployer release to qa</code></li>
<li><code>mix edeliver restart qa</code></li>
<li><code>bin/ide start</code></li>
<li><code>bin/ide attach</code> -> quit with ^D, not ^c (will kill process)</li>
<li><code>bin/ide remote_console</code></li>
<li><code>mix edeliver build upgrade --with=0.1.0+232424323-hdhfd</code></li>
<li><code>mix edeliver deploy upgrade to qa</code> -> will prompt for version
number</li>
</ul>
</li>
</ul>


<h2>Chef</h2>

<ul>
<li>server provisioning

<ul>
<li>consistency, automation</li>
</ul>
</li>
<li>inheritance in the cookbooks, base cookbook -> security</li>
<li>like ruby base cookbooks</li>
<li><a href="https://blog.chef.io/2013/12/03/doing-wrapper-cookbooks-right/">wrapper cookbook</a>, like forking a cookbook without modifying it

<ul>
<li>increasing levels of abstraction</li>
</ul>
</li>
<li>conventions of chef aren&#8217;t very clearly defined</li>
<li>differences between recipes and cookbooks?</li>
</ul>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <!-- Now we're back to normal posts. Note the links used under href in both headers.-->
        <h1 class="entry-title"><a href="/blog/elastic-search/">Elastic Search</a></h1>
      
    
    
      <p class="meta">
        








  


<time datetime="2017-03-10T11:38:00-05:00" pubdate data-updated="true">Mar 10<span>th</span>, 2017</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h2>Intro</h2>

<p>&#8220;elastic search is full text sreach engine, non-relational DB, analytics engine&#8221;</p>

<ul>
<li>has clustering and managed over REST</li>
<li><p>Suggest Explicit mapping</p></li>
<li><p>keywords -> non-analyzed data</p></li>
<li><p>full text -> analyzed</p></li>
<li><p>filters -> will need <code>bool</code> then <code>filters</code></p></li>
</ul>


<h2>relevance -> score meta data field for document match</h2>

<ul>
<li>things are ranked</li>
<li>filters are faster and don&#8217;t have relevance (so if you don&#8217;t care, go with fiters)</li>
<li>can boost relevance</li>
</ul>


<h2>multi-index multi-type</h2>

<ul>
<li>lots of power</li>
</ul>


<h2>Aggregation -> group by on steroids</h2>

<ul>
<li>SQL: group by the bucket</li>
<li>aggregator -> can do nested group by and data retrieval</li>
</ul>


<h2>Managing elastic search</h2>

<ul>
<li>clustering

<ul>
<li>odd number of nodes bigger than 1

<ul>
<li>3 shards and replication</li>
<li>a third node can shuffle the shards and the replicas</li>
</ul>
</li>
</ul>
</li>
</ul>


<h2>ELK Stack</h2>

<ul>
<li>elastic search, logstash, and kubana</li>
<li>logstash

<ul>
<li>want to parse and stash log data</li>
</ul>
</li>
<li>kubana

<ul>
<li>front end visualizer</li>
</ul>
</li>
<li>now beats added -> lightweight, written in go -> for shipping</li>
</ul>


<h2>Split Brain issue</h2>

<ul>
<li><a href="http://blog.trifork.com/2013/10/24/how-to-avoid-the-split-brain-problem-in-elasticsearch/">HOW TO AVOID THE SPLIT-BRAIN PROBLEM IN ELASTICSEARCH</a></li>
</ul>


<h2>Tinc</h2>

<ul>
<li>VPN -> encrypts traffic between servers</li>
</ul>


<h2>Setting up elastic search</h2>

<ul>
<li><a href="https://www.digitalocean.com/community/tutorials/how-to-install-and-configure-elasticsearch-on-ubuntu-16-04">setting up a elasticsearch cluster on ubuntu</a></li>
<li>used a ruby case statement to set the master versus the replicas up</li>
<li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/_basic_concepts.html">shards, replicas, documents explained</a></li>
<li><a href="https://qbox.io/blog/launching-and-scaling-elasticsearch">Thoughts on Launching and Scaling Elasticsearch</a></li>
<li><a href="https://qbox.io/blog/optimizing-elasticsearch-how-many-shards-per-index">optimizing sharding</a>

<ul>
<li><code>A good launch point for capacity planning is to allocate shards with a factor of 1.5 to 3 times the number of nodes in your initial configuration. If you're starting with 3 nodes, then we recommend that you specify at most 3 x 3 = 9 shards.</code></li>
<li><code>We reiterate that shards consume resources and require processing overhead.</code></li>
</ul>
</li>
<li>needed to bump vm.max_map_count according to <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/vm-max-map-count.html">these instructions</a></li>
</ul>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <!-- Now we're back to normal posts. Note the links used under href in both headers.-->
        <h1 class="entry-title"><a href="/blog/preparing-data-for-machine-learning/">Preparing Data for Machine Learning</a></h1>
      
    
    
      <p class="meta">
        








  


<time datetime="2017-03-10T10:02:00-05:00" pubdate data-updated="true">Mar 10<span>th</span>, 2017</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h2>Why machine learning - you can predict the future</h2>

<ul>
<li>Explosion of data, more available than ever</li>
<li>sheer processing power available at a reasonable price point</li>
</ul>


<h2>Data Preparation Tools</h2>

<ul>
<li>Rstudio -> data prep and execute the machine learning</li>
<li>jupyter notebooks -> python in the cloud</li>
<li>excel -> stick with the tools you know</li>
<li>azure machine learning studio</li>
<li>scikit learn (competitor to r studio) for python</li>
<li>relational database tools (SQL queries)</li>
<li>sed / awk</li>
<li>python, r, sql most common languages to clean up data</li>
</ul>


<h2>Data Cleaning</h2>

<ul>
<li>missing values in data or repeating values in data (blanks, null,
n/a, unknown, 999999)</li>
<li>what&#8217;s your business goal?

<ul>
<li>SPCA - can you help us predict what animals won&#8217;t get adopted?</li>
<li>got enough data to be significant, you can delete rows -> not
always an option</li>
</ul>
</li>
<li>can substitute a specific value (can go with a worst case
scenario)</li>
<li>fill forward and fill backwards based on the last value we read ->
going to have to write code</li>
<li>R is.na()</li>
<li><p>python pandas.fillna(), pandas.isnull()</p></li>
<li><p>excel tips -></p>

<ul>
<li>select individual columns, go to special, select blanks (will
select every blank cell) and you can enter a value</li>
</ul>
</li>
<li><p>repeated values</p>

<ul>
<li>causes a bias in the data</li>
<li>duplicate row vs duplicate IDs</li>
<li>r duplicated()</li>
<li>python dataframe.drop_duplicates</li>
<li>SQL DISTINCT or correctlated queries</li>
<li>correlated subquery -> if the rows are the same but the IDs are different when you find
two identitical records and delete the one with the lower ID
number</li>
</ul>
</li>
</ul>


<h2>Data Transformation</h2>

<ul>
<li>Decomposition

<ul>
<li>the more you know about the data, the better</li>
<li>one column represents two or more values (like addresses lumped
together and finding the city and state)</li>
<li>return a 1 or 0 to represented spayed and nuetered</li>
</ul>
</li>
<li><p>Aggregation</p>

<ul>
<li>how many copies of different books to keep in stock?</li>
<li>don&#8217;t want the day it was sold, want total number of books sold
per wk/mon x date</li>
<li>select count(*) from sales group by (books sold per period)</li>
</ul>
</li>
<li><p>Scaling</p>

<ul>
<li>predict how long a patient admitted the flu will need to stay in
the hospital</li>
<li>because the age has a wider varience in age you don&#8217;t see the
lower differences like temperatute

<ul>
<li>create ranges -> normalizing, standardizing</li>
</ul>
</li>
</ul>
</li>
</ul>


<h2>Conclusion</h2>

<ul>
<li><p>Training data versus test data</p>

<ul>
<li>subject matter experts become important as they need to undetr</li>
<li>tumors -> which do you want, one with more false positives and one
with more false negatives</li>
</ul>
</li>
<li><p>slides at <code>aka.ms/confooml</code></p></li>
<li>data science and machine learning essentials</li>
<li>cleaning data with python</li>
<li>building your first machine learning experiment</li>
</ul>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <!-- Now we're back to normal posts. Note the links used under href in both headers.-->
        <h1 class="entry-title"><a href="/blog/the-soul-in-the-machine-developing-for-humans/">The Soul in the Machine - Developing for Humans</a></h1>
      
    
    
      <p class="meta">
        








  


<time datetime="2017-03-09T13:07:00-05:00" pubdate data-updated="true">Mar 9<span>th</span>, 2017</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>With Christian Heilmann</p>

<h2>Machines vs. Humans</h2>

<ul>
<li>machines don&#8217;t get tired or make mistake as they fatigue</li>
<li>law is boring and machines don&#8217;t get bored</li>
<li>The future of employement -> company secretaries</li>
<li>machines handle grunt work and humans handle human decisions -> the
more abstract the less likely you are to be replaced by a computer</li>
<li>the more predictable we are as programmers, the more likely we are
going to be replaced</li>
<li>AI software that makes AI software</li>
<li>past being factory workers and finding the way to add value</li>
<li>the saddest aspect of life right now is that science gathers
knowledge faster than society gathers wisdom.</li>
<li>just making money isn&#8217;t enough anymore</li>
<li>Orwell predicted cameras everyone but didn&#8217;t predict we would buy the camera</li>
<li>&#8220;Technological progress has merely provided us with more efficient
means for going backwards.&#8221; -> Aldous Huxley</li>
<li>&#8220;the power of big data and psychographics&#8221;</li>
<li>inclusive design set that microsoft released</li>
<li>it&#8217;s not about allowing access but avoiding barriers</li>
<li>spotlight - show me my documents larger than 20 pages</li>
<li>netflix -> fast movement can be compressed more than slow movement</li>
<li>Aipoly -> identify objects on the phone, not running on the internet</li>
<li>facebook open sourced identifying objects</li>
<li>AI lip reading for 46% accuracy, humans have 12% accuracy</li>
<li>imagenet and open images dataset -> image data sets, properly
trained data sets to play with</li>
<li><code>captionbot.ai</code></li>
</ul>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <!-- Now we're back to normal posts. Note the links used under href in both headers.-->
        <h1 class="entry-title"><a href="/blog/intro-to-dns/">Intro to DNS</a></h1>
      
    
    
      <p class="meta">
        








  


<time datetime="2017-03-09T11:00:00-05:00" pubdate data-updated="true">Mar 9<span>th</span>, 2017</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>With Maarten Balliauw</p>

<ul>
<li>people know should more about DNS and the http level</li>
</ul>


<h2>DNS 101</h2>

<ul>
<li><p>How the internet works</p>

<ul>
<li>IPv4 or IPv6</li>
<li>Check own operating system files to see if the host file has a
record is known</li>
<li>will check the DNS cache for the local machine</li>
<li>OS will ask the router and check its own host file and DNS cache</li>
<li>same process for the ISP</li>
<li>the ISP will then go to the root server, address of the
authoritative server</li>
<li><p>6 hubs look ups</p></li>
<li><p><code>nslookup google.com</code></p></li>
<li><p><code>dig A google.com +trace</code></p></li>
<li><p>two types of servers</p>

<ul>
<li>authorative (owns the domain)</li>
<li>cache (recursor) -> resolves the domain for you</li>
</ul>
</li>
<li>DNS protcol designed in 1983

<ul>
<li>designed to map a domain name to an IP address</li>
<li>added TXT records and IPv6</li>
</ul>
</li>
<li>TLD managed by separate organizatons (verisign, canadian internet
registrartion authority)

<ul>
<li>all make their own rules e.g. need to be a canadian to be a .ca
domain name, transfer rules</li>
</ul>
</li>
<li>hierarchical system:

<ul>
<li>hit <code>.</code> first</li>
<li>then TLD like <code>org, com, ca</code></li>
<li>can also create maps within a specific domain and could create
own hierarchy like google does</li>
</ul>
</li>
<li>caches

<ul>
<li>TTL -</li>
<li>cannot clear cache at ISP</li>
<li>keep the old IP address to maintain both</li>
</ul>
</li>
</ul>
</li>
<li><p>DNS zones</p>

<ul>
<li>UDP protocol</li>
<li>only 13 root servers across the world</li>
<li><code>root-servers.org</code></li>
<li>$100k/yr to get own TLD</li>
<li><p>? where does the money for those fees go for buying a TLD?</p></li>
<li><p>a text file and are hierarchical</p></li>
<li>SOA -> start of authority</li>
<li><p>Name of authoritive master name server (NA)</p></li>
<li><p>CNAME - redirect at the DNS record</p></li>
<li>MX - find mail server at specific address</li>
<li>TXT - validate domain ownership/spam rules</li>
<li>SRV - descibes a service type and port (like for in network
printer)</li>
<li><p>PTR - reverse DNS</p></li>
<li><p>zone transfers</p>

<ul>
<li>most IPs require more than 1 nameserver</li>
<li>master name server and that will sync with slave nameservers</li>
<li>no authentication and may expose internal services</li>
</ul>
</li>
</ul>
</li>
</ul>


<h2>Security</h2>

<ul>
<li>old protocol</li>
<li>cache poisoning</li>
<li>DNSSEC - checks the origin - certificate chain</li>
<li><p>most modern browsers are checking for DNSSEC records</p></li>
<li><p>DDoS</p>

<ul>
<li>lots of open resolvers out there</li>
<li>DNS amplication for DDos</li>
<li>disable recursion</li>
</ul>
</li>
</ul>


<h2>DNS in application archtecture</h2>

<ul>
<li>DNS failover and load balancing</li>
<li>add multiple DNS records -> will be a poor man&#8217;s load balancer
because it will return an random record</li>
<li>intelligence DNS server (CNS)</li>
<li>configuration in DNS

<ul>
<li>use DNS as a configuration store</li>
<li>DNS record could point to a TXT value</li>
</ul>
</li>
<li>service discovery</li>
</ul>


<h2>DNS for fun and profit</h2>

<ul>
<li><p>Abusing DNS</p>

<ul>
<li>public hotspots</li>
<li>proxy server translating HTTP</li>
</ul>
</li>
<li><p>iodine - same HTTP over DNS - tunnel traffic</p>

<ul>
<li><code>code.kryo.se/iodine</code></li>
</ul>
</li>
</ul>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <!-- Now we're back to normal posts. Note the links used under href in both headers.-->
        <h1 class="entry-title"><a href="/blog/7-righteous-fights/">7 Righteous Fights</a></h1>
      
    
    
      <p class="meta">
        








  


<time datetime="2017-03-09T10:03:00-05:00" pubdate data-updated="true">Mar 9<span>th</span>, 2017</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>With Heidi Waterhouse</p>

<ul>
<li>Technical debt compounds in a way that is painful</li>
</ul>


<h2>Localization</h2>

<ul>
<li>get them early, reference labels -> will make it so much easier
later</li>
<li>no words in logos or images</li>
</ul>


<h2>Distributon</h2>

<h2>Security</h2>

<ul>
<li>use 3rd party people that do this</li>
<li>leave room for encryption</li>
<li>sunset your data after a certain period</li>
</ul>


<h2>Extensibility</h2>

<ul>
<li> make your work modifiable</li>
</ul>


<h2>Documentation</h2>

<ul>
<li>documentation helps us with onboarding and reduces context switches
for seniors</li>
<li>production scripts and build sequences need to be recorded</li>
</ul>


<h2>Affordance</h2>

<ul>
<li>tells us what we are doing without documentation</li>
</ul>


<h2>Acceptance</h2>

<ul>
<li>have you showed this product to anyone who is like the user (not the
financiers) -> need to actually talk to them</li>
<li>show them the product and don&#8217;t tell them how it supposed to work is
the hardest and most important part</li>
<li>&#8220;Making users awesome&#8221; - people don&#8217;t want to be using software,
they want to be drawing or taking a photograph, software is just an
intermediary</li>
</ul>


<h2>Accessiblity</h2>

<ul>
<li>look at this on a non-retina screen</li>
<li>emulators and physical are totally different experiences</li>
<li>8% of men are red-green color blind</li>
<li> status updates for nagios use red-green, which isn&#8217;t helpful</li>
<li>hide your mouse, use TAB instead</li>
<li>we are all temporarily able-bodied</li>
</ul>


<h2>Tactics</h2>

<ul>
<li>Learn how to write ROI documents</li>
<li>diverse teams will help with these problems</li>
<li>money is the root of all business decisons</li>
<li>be productively lazy</li>
</ul>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <!-- Now we're back to normal posts. Note the links used under href in both headers.-->
        <h1 class="entry-title"><a href="/blog/databases-with-brad-urani/">Databases With Brad Urani</a></h1>
      
    
    
      <p class="meta">
        








  


<time datetime="2017-03-09T08:42:00-05:00" pubdate data-updated="true">Mar 9<span>th</span>, 2017</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Brad Urani @confoo</p>

<h3>ACID -></h3>

<ul>
<li>atomicity: all or nothing. If one of 3 writes fails it rolls it back</li>
<li>Consistency:</li>
<li>Isolation:</li>
<li><p>Durability: DB survives</p></li>
<li><p>no-sql aren&#8217;t faster because of algorithms, they are faster because they did it because they did away with the guarantees</p></li>
</ul>


<p>google spanner - reliable network because it&#8217;s with in their own fiber optics</p>

<h3>SQL is declarative language</h3>

<ul>
<li>don&#8217;t give the computer exact instructions. Giving the comp a rough outline and the DB.</li>
</ul>


<h3>index is a tree</h3>

<ul>
<li>binary tree</li>
<li>doubled the size of the tree but only increased by 33%  - O(log n)</li>
<li>balanced tree -> rebalancing in order to make it as fast as possible</li>
<li>why not add indexes to everything

<ul>
<li>disk space and inserts</li>
</ul>
</li>
</ul>


<h3>Quick sort</h3>

<ul>
<li>fastest, but not that fast for records on disk</li>
</ul>


<h3>Merge sort</h3>

<ul>
<li>divide and conquor algorithm</li>
<li>O(n log n)</li>
</ul>


<h3>Joins:</h3>

<ul>
<li>nested loop JOINs - O(n<sup>2)</sup></li>
</ul>


<h3>Hash Join -> O(n)</h3>

<ul>
<li>Hash tables -> values are pointers because they are in linked lists

<ul>
<li>building the hash table from the beginning is expensive.</li>
<li>MD5? go with a bit key that doesn&#8217;t guarantee no collisions</li>
</ul>
</li>
<li>good for lots of duplicates</li>
</ul>


<h3>Merge Join -> O(m log n)</h3>

<ul>
<li>lists are already sorted.</li>
</ul>


<h3>Query plans</h3>

<ul>
<li>explain or explain analyze -> can tune the query to be faster</li>
</ul>


<h3>natural selection process for finding the best query plan</h3>

<ul>
<li>like genetic selection</li>
<li>doing all this in milliseconds</li>
<li>Evaluation -> selection -> crossover -> mutation</li>
</ul>


<h3>Caching</h3>

<ul>
<li>cache warmup period</li>
<li>Least recently used (LRU) in memory cache</li>
</ul>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <!-- Now we're back to normal posts. Note the links used under href in both headers.-->
        <h1 class="entry-title"><a href="/blog/working-to-make-myself-obsolete/">Working to Make Myself Obsolete</a></h1>
      
    
    
      <p class="meta">
        








  


<time datetime="2016-11-26T12:23:00-05:00" pubdate data-updated="true">Nov 26<span>th</span>, 2016</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>When I told my mother, an executive of 30 years mostly spent at <a href="http://www.crabtree-evelyn.com/">Crabtree and Evelyn</a>, about my goal to make myself obsolete she flipped.</p>

<p>&#8220;You are working yourself out of your job,&#8221; she warned. &#8220;You need to be doing the opposite.&#8221;</p>

<p>My mom fought through sexism for decades to maintain her influential role at the top of the hierarchy. My mother is a scrapper and she clearly had to defend her territory. From her advice on management issues however, it seems pretty clear to me she probably never got ahead of the tsunami of work that consumes managers’ everyday lives. I mostly observe managers fire fighting and doing implementation. This is a trap. We all want to feel important, but if managers are the single point of failure, things will fall apart.</p>

<p>I’ve mused about my take on <a href="/blog/my-take-on-maker-versus-manager/">maker versus manager</a>, it can be hard to let go, but those that never let go of the hybrid role are doomed. The manager may not be, but the team is. We owe it to our reports to make sure we have the time to properly manage them. It feeds our egos to have a full calendar and lots of “important” decisions to make, but if that’s all we do then we will eventually drown in our own self-importance rather than develop the people on our team to help shoulder the load. Scale will break us.</p>

<p>So thanks mom for the advice, but I still strive to make myself obsolete, so the world will continue to spin without me. So I can go on vacation without stressing. So I can dedicate a good chunk of my week to 1 on 1s and so my lieutenants feel qualified and empowered to make the calls shape our team and product. I may be working myself out of a job, but at least I feel like I’m going to do this one right.</p>
</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/blog/page/2/">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/more-ops-notes/">More Ops Notes</a>
      </li>
    
      <li class="post">
        <a href="/blog/project-aristole/">Project Aristole</a>
      </li>
    
      <li class="post">
        <a href="/blog/crash-course/">Crash Course DevOps</a>
      </li>
    
      <li class="post">
        <a href="/blog/elastic-search/">Elastic Search</a>
      </li>
    
      <li class="post">
        <a href="/blog/preparing-data-for-machine-learning/">Preparing Data for Machine Learning</a>
      </li>
    
  </ul>
</section>





  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2017 - Adam Jonas -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'ajonas';
      
        
        var disqus_script = 'count.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>











</body>
</html>
